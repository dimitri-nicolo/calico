# imagePullSecrets is a special helm field which, when specified, creates a secret
# containing the pull secret which is used to pull all images deployed by this helm chart and the resulting operator.
# this field is a map where the key is the desired secret name and the value is the contents of the imagePullSecret.
#
# Example: --set-file imagePullSecrets.gcr=./pull-secret.json
imagePullSecrets: {}
installation:
  enabled: true
  variant: TigeraSecureEnterprise
  kubernetesProvider: ""
  # imagePullSecrets are configured on all images deployed by the tigera-operator.
  # secrets specified here must exist in the tigera-operator namespace; they won't be created by the operator or helm.
  # imagePullSecrets are a slice of LocalObjectReferences, which is the same format they appear as on deployments.
  #
  # Example: --set installation.imagePullSecrets[0].name=my-existing-secret
  imagePullSecrets: []
apiServer:
  enabled: true
# When enabled a subchart called tigera-prometheus-operator will be installed.
# Set the tags and subchart to false if you want to bring your own Prometheus
# operator to your cluster.
# Alternatively, you can pass the following flags to your installation command:
#   --set tags.tigera-prometheus-operator=false
#   --set tigera-prometheus-operator.enabled=false
tigera-prometheus-operator:
  enabled: true
tags:
  tigera-prometheus-operator: true
intrusionDetection:
  enabled: true
logCollector:
  enabled: true
logStorage:
  enabled: true
  nodes:
    count: 1
manager:
  enabled: true
monitor:
  enabled: true
compliance:
  enabled: true
policyRecommendation:
  enabled: true
authentication:
  enabled: false
applicationLayer:
  enabled: false
amazonCloudIntegration:
  enabled: false
defaultFelixConfiguration:
  enabled: false
# MCM configuration options.
# Management cluster.
managementCluster:
  enabled: false
  address:
  service:
    enabled: false
    type:
    port: 9449
    nodePort:
    targetPort: 9449
    protocol: TCP
    annotations:
      - key:
        value:
managedClusters:
  enabled: false
  clusters:
    - name:
      certificate:
# Managed cluster.
managementClusterConnection:
  enabled: false
  managementClusterAddress:
  management:
    base64:
      tls:
        crt:
    tls:
      crt:
  managed:
    base64:
      tls:
        crt:
        key:
    tls:
      crt:
      key:
# Optional configuration for setting custom BGP templates where
# key is the filename of the template and value is the contents of the template.
bgp: {}
certs:
  node:
    key:
    cert:
    commonName:
  typha:
    key:
    cert:
    commonName:
    caBundle:
  manager:
    key:
    cert:
  elasticsearch:
    key:
    cert:
  kibana:
    key:
    cert:
  apiServer:
    key:
    cert:
  compliance:
    key:
    cert:
# Resource requests and limits for the tigera/operator pod.
resources: {}
# Tolerations for the tigera/operator pod.
tolerations:
  - effect: NoExecute
    operator: Exists
  - effect: NoSchedule
    operator: Exists
# NodeSelector for the tigera/operator pod.
nodeSelector:
  kubernetes.io/os: linux
# Affinity for the tigera/operator pod.
affinity: {}
# PriorityClassName for the tigera/operator pod.
priorityClassName: ""
# Custom annotations for the tigera/operator pod.
podAnnotations: {}
# Custom labels for the tigera/operator pod.
podLabels: {}
# Image and registry configuration for the tigera/operator pod.
tigeraOperator:
  image: tigera/operator
  version: v1.34.1
  registry: quay.io
calicoctl:
  enabled: false
  image: quay.io/tigera/calicoctl
  tag: v3.19.1
  binPath: /bin
techPreviewOptions:
  # set to name of desired apparmor policy for the calico-node container and
  # pod will be annotated with 'container.apparmor.security.beta.kubernetes.io/calico-node'
  nodeApparmorPolicyName: ""
kubeletVolumePluginPath: /var/lib/kubelet
# Optionally configure the host and port used to access the Kubernetes API server.
kubernetesServiceEndpoint:
  host: ""
  port: "6443"
