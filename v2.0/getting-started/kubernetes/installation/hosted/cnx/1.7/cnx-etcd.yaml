---
layout: null
---
# This manifest adds the additional CNX Manager components to a cluster
# that has already had the Calico part of CNX deployed.
# - It refers to the calico-config ConfigMap and calico-etcd-secrets Secret
#   from that file, so if you are not using the provided hosted Calico
#   manifest you must update references to those resources in this file.
# - Update the tigera-cnx-manager-config ConfigMap below before use.
# - Optionally update the cnx-apiserver-certs ConfigMap below before use to
#   enable TLS on the connection between the CNX API server and the
#   Kubernetes API server.
# - This manifest makes the CNX Manager web server available via a NodePort
#   serving on port 30003.  You may wish to update how this is exposed; do
#   so by editing the tigera-cnx-manager-access Service below.

# Update this ConfigMap with the Google login client id.
kind: ConfigMap
apiVersion: v1
metadata:
  name: tigera-cnx-manager-config
  namespace: kube-system
data:
  # Authentication type.  Must be set to "OIDC", "Basic" or "Token".
  tigera.cnx-manager.authentication-type: "Basic"
  # The OIDC authority.  Required if authentication-type is OIDC, ignored otherwise.
  tigera.cnx-manager.oidc-authority: "https://accounts.google.com"
  # The OIDC client id to use for OIDC login.  Kubelet must be configured accordingly.
  # Value is ignored if not using OIDC login.
  tigera.cnx-manager.oidc-client-id: "<fill-in-your-oauth-client-id-here>"
  # The location of the Kubernetes API.  This must be reachable from where the web interface
  # will be accessed from.
  tigera.cnx-manager.kubernetes-api: "127.0.0.1:6443"

---

# Optionally update this ConfigMap to enable TLS between the CNX API
# server and Kubernetes API server.
apiVersion: v1
kind: Secret
type: Opaque
metadata:
  name: cnx-apiserver-certs
  namespace: kube-system
data:
  # Populate the following files with etcd TLS configuration if desired,
  # but leave blank if not using TLS for Kubernetes etcd.
  # This self-hosted install expects three files with the following names.  The values
  # should be base64 encoded strings of the entire contents of each file.
  #apiserver.key:
  #apiserver.crt:

---

# Optionally update this Service to change how CNX Manager is accessed.
# If using Google login, the URL for the web server must be configured
# as a redirect URI in the Google project.  If the web server will be
# accessed at https://<host>:<port>, add https://<host>:<port>/login/oidc/callback
# to the redirect URI list for the project.
apiVersion: v1
kind: Service
metadata:
  labels:
    k8s-app: cnx-manager
  name: cnx-manager
  namespace: kube-system
spec:
  selector:
    k8s-app: cnx-manager
  ports:
    - port: 8080
      targetPort: 443
      nodePort: 30003
  type: NodePort

---

apiVersion: apiregistration.k8s.io/v1beta1
kind: APIService
metadata:
  name: v3.projectcalico.org
spec:
  insecureSkipTLSVerify: true
  group: projectcalico.org
  versionPriority: 200
  groupPriorityMinimum: 200
  service:
    name: api
    namespace: kube-system
  version: v3

---

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: calico:system:auth-delegator
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:auth-delegator
subjects:
- kind: ServiceAccount
  name: cnx-apiserver
  namespace: kube-system

---

apiVersion: rbac.authorization.k8s.io/v1beta1
kind: RoleBinding
metadata:
  name: calico-auth-reader
  namespace: kube-system
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: extension-apiserver-authentication-reader
subjects:
- kind: ServiceAccount
  name: cnx-apiserver
  namespace: kube-system

---

kind: ServiceAccount
apiVersion: v1
metadata:
  name: cnx-apiserver
  namespace: kube-system

---

kind: ServiceAccount
apiVersion: v1
metadata:
  name: cnx-manager
  namespace: kube-system

---

apiVersion: v1
kind: Service
metadata:
  name: api
  namespace: kube-system
spec:
  ports:
  - port: 443
    protocol: TCP
    targetPort: 5443
  selector:
    apiserver: "true"

---

apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: cnx-apiserver
  namespace: kube-system
  labels:
    apiserver: "true"
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      apiserver: "true"
  template:
    metadata:
      name: cnx-apiserver
      namespace: kube-system
      labels:
        apiserver: "true"
    spec:
      serviceAccountName: cnx-apiserver
      tolerations:
        - key: node-role.kubernetes.io/master
          effect: NoSchedule
      containers:
      - name: cnx-apiserver
        image: {{page.registry}}{{site.imageNames["cnxApiserver"]}}:{{site.data.versions[page.version].first.components["cnx-apiserver"].version}}
        args:
        - "--secure-port=5443"
        env:
          - name: ETCD_ENDPOINTS
            valueFrom:
              configMapKeyRef:
                name: calico-config
                key: etcd_endpoints
          - name: DATASTORE_TYPE
            value: "etcdv3"
          # If you're using TLS enabled etcd uncomment the following.
          # Location of the CA certificate for etcd.
          # - name: ETCD_CA_CERT_FILE
          #   valueFrom:
          #     configMapKeyRef:
          #       name: calico-config
          #       key: etcd_ca
          # Location of the client key for etcd.
          # - name: ETCD_KEY_FILE
          #   valueFrom:
          #     configMapKeyRef:
          #       name: calico-config
          #       key: etcd_key
          # Location of the client certificate for etcd.
          # - name: ETCD_CERT_FILE
          #   valueFrom:
          #     configMapKeyRef:
          #       name: calico-config
          #       key: etcd_cert
        volumeMounts:
          # - mountPath: /calico-secrets
          #   name: etcd-certs
          # - mountPath: /code/apiserver.local.config/certificates
          #   name: apiserver-certs
      volumes:
        # If you're using TLS enabled etcd uncomment the following.
        # - name: etcd-certs
        #   secret:
        #     secretName: calico-etcd-secrets
        # If you're using TLS with certificate verification then 
        # uncomment the following.
        # - name: apiserver-certs
        #   secret:
        #     secretName: cnx-apiserver-certs

---

apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: cnx-manager
  namespace: kube-system
  labels:
    k8s-app: cnx-manager
spec:
  replicas: 1
  strategy:
    type: Recreate
  template:
    metadata:
      name: cnx-manager
      namespace: kube-system
      labels:
        k8s-app: cnx-manager
      annotations:
        # Mark this pod as a critical add-on; when enabled, the critical add-on scheduler
        # reserves resources for critical add-on pods so that they can be rescheduled after
        # a failure.  This annotation works in tandem with the toleration below.
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      serviceAccountName: cnx-manager
      tolerations:
      - key: node-role.kubernetes.io/master
        effect: NoSchedule
      # Allow this pod to be rescheduled while the node is in "critical add-ons only" mode.
      # This, along with the annotation above marks this pod as a critical add-on.
      - key: CriticalAddonsOnly
        operator: Exists
      containers:
      - name: cnx-manager
        image: {{page.registry}}{{site.imageNames["cnxManager"]}}:{{site.data.versions[page.version].first.components["cnx-manager"].version}}
        env:
          - name: CNX_WEB_AUTHENTICATION_TYPE
            valueFrom:
              configMapKeyRef:
                name: tigera-cnx-manager-config
                key: tigera.cnx-manager.authentication-type
          - name: CNX_WEB_OIDC_AUTHORITY
            valueFrom:
              configMapKeyRef:
                name: tigera-cnx-manager-config
                key: tigera.cnx-manager.oidc-authority
          - name: CNX_WEB_OIDC_CLIENT_ID
            valueFrom:
              configMapKeyRef:
                name: tigera-cnx-manager-config
                key: tigera.cnx-manager.oidc-client-id
          - name: CNX_WEB_K8S_API
            valueFrom:
              configMapKeyRef:
                name: tigera-cnx-manager-config
                key: tigera.cnx-manager.kubernetes-api
        volumeMounts:
        - mountPath: /etc/cnx-manager-web-tls
          name: cnx-manager-tls
      volumes:
      - name: cnx-manager-tls
        secret:
          secretName: cnx-manager-tls
