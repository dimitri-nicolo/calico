// Copyright (c) 2021-2022 Tigera, Inc. All rights reserved.

package handlers

import (
	"archive/tar"
	"archive/zip"
	"bytes"
	"context"
	"errors"
	"fmt"
	"io"
	"mime"
	"net/http"
	"regexp"
	"strconv"
	"strings"
	"time"

	log "github.com/sirupsen/logrus"

	cerrors "github.com/projectcalico/calico/libcalico-go/lib/errors"
	"github.com/projectcalico/calico/packetcapture/pkg/cache"
	"github.com/projectcalico/calico/packetcapture/pkg/capture"
	"github.com/projectcalico/calico/packetcapture/pkg/middleware"

	v3 "github.com/tigera/api/pkg/apis/projectcalico/v3"
)

const ignoringTarError = "tar: removing leading '/' from member names"

// Files defines the logic and http handler needed to retrieve/delete the files generated by a packet capture.
// For each node that contains packet capture files, it will launch a remote pod/exec command and bundle
// the files as a zip archive.
// For each node that contains packet capture files, it will launch a remote pod/exec command to delete all files.
type Files struct {
	capture.K8sCommands
	capture.FileCommands
	cache.ClientCache
	ignoreTarDeleteRegex *regexp.Regexp
}

// NewFiles creates a new Files structure
func NewFiles(cache cache.ClientCache, k8sCommands capture.K8sCommands, retrieval capture.FileCommands) *Files {
	ignoreTarDeleteRegex, _ := regexp.Compile("tar: (.)+: No such file or directory")

	return &Files{
		K8sCommands:          k8sCommands,
		FileCommands:         retrieval,
		ClientCache:          cache,
		ignoreTarDeleteRegex: ignoreTarDeleteRegex,
	}
}

// Download is a http handler that returns the files generated by a packet capture as a zip archive
func (f *Files) Download(w http.ResponseWriter, r *http.Request) {
	log.Infof("received the following request %s", r.RequestURI)

	if r.Method != http.MethodGet {
		http.Error(w, "Method not supported", http.StatusMethodNotAllowed)
	}

	var namespace = middleware.NamespaceFromContext(r.Context())
	var captureName = middleware.CaptureNameFromContext(r.Context())
	var clusterID = middleware.ClusterIDFromContext(r.Context())

	packetCapture, err := f.K8sCommands.GetPacketCapture(clusterID, captureName, namespace)
	if err != nil {
		log.WithError(err).Errorf("failed to get packet capture %s/%s", namespace, captureName)
		switch err.(type) {
		case cerrors.ErrorResourceDoesNotExist:
			http.Error(w, err.Error(), http.StatusNotFound)
			return
		default:
			http.Error(w, err.Error(), http.StatusInternalServerError)
			return
		}
	}

	if f.hasNoFiles(packetCapture) {
		w.WriteHeader(http.StatusNoContent)
		return
	}

	var b bytes.Buffer
	var zipWriter = zip.NewWriter(&b)
	var filesRead = 0
	for _, file := range packetCapture.Status.Files {
		log.Debugf("copying files %v", file.FileNames)
		entryPod, err := f.K8sCommands.GetEntryPod(clusterID, file.Node)
		if err != nil {
			log.WithError(err).Errorf("failed to locate entry pods for %s/%s", namespace, captureName)
			continue
		}
		var entryPoint = capture.EntryPoint{
			EntryPod: *entryPod,

			CaptureDirectory: file.Directory,
			CaptureName:      captureName,
			CaptureNamespace: namespace,
		}
		log.Debugf("entry pods is %v", entryPoint)

		reader, errorReader, err := f.FileCommands.OpenTarReader(clusterID, entryPoint)
		if err != nil {
			log.WithError(err).Errorf("failed to create a remote command to retrieve the files from %v", entryPoint)
			continue
		}

		// Start reading and compress files in a zip archive
		if reader != nil {
			var tarReader = tar.NewReader(reader)
			for {
				header, err := tarReader.Next()
				if err != nil {
					if err != io.EOF {
						log.WithError(err).Errorf("failed to read stream from %s", file.Node)
						continue
					}
					break
				}

				if header.FileInfo().IsDir() {
					continue
				}

				filesRead++
				zipHeader, err := zip.FileInfoHeader(header.FileInfo())
				if err != nil {
					log.WithError(err).Errorf("failed to write tar header to archive file %s from node %s", header.FileInfo().Name(), file.Node)
					continue
				}

				zipHeader.Method = zip.Deflate
				writer, err := zipWriter.CreateHeader(zipHeader)
				if err != nil {
					log.WithError(err).Errorf("failed to create zip header for file %s from node %s", header.FileInfo().Name(), file.Node)
					continue
				}
				var written int64
				written, err = io.Copy(writer, tarReader)
				if err != nil {
					log.WithError(err).Errorf("zip writer failed to add file %s from node %s", header.FileInfo().Name(), file.Node)
					continue
				}
				log.Debugf("zip writer written %d for file %s (size = %d)", written, header.FileInfo().Name(), header.FileInfo().Size())

				zipWriter.Flush()
			}
		}

		// Read the error from the stream
		err = readErrorFromStream(errorReader)
		if err != nil && !strings.Contains(err.Error(), ignoringTarError) && !f.ignoreTarDeleteRegex.MatchString(err.Error()) {
			log.WithError(err).Error("remote command failed")
		}
	}

	// Close the zip writer
	zipWriter.Close()

	if filesRead > 0 {
		// Write headers for the request
		cd := mime.FormatMediaType("attachment", map[string]string{"filename": middleware.ZipFiles})
		w.Header().Set("Content-Disposition", cd)
		w.Header().Set("Content-Length", strconv.FormatInt(int64(b.Len()), 10))
		if written, err := io.Copy(w, &b); err != nil {
			log.WithError(err).Errorf("failed to copy to http response writer. expected = %d but actual = %d", b.Len(), written)
		}
	} else {
		// Return 204 No Content
		w.WriteHeader(http.StatusNoContent)
	}
}

func (f *Files) hasNoFiles(packetCapture *v3.PacketCapture) bool {
	if len(packetCapture.Status.Files) == 0 {
		return true
	}

	var reportedFiles = 0
	for _, filesPerNode := range packetCapture.Status.Files {
		reportedFiles = reportedFiles + len(filesPerNode.FileNames)
	}

	return reportedFiles == 0
}

func readErrorFromStream(errorReader io.Reader) error {
	if errorReader == nil {
		return nil
	}
	var errorBuffer bytes.Buffer
	var _, err = io.Copy(&errorBuffer, errorReader)
	if err != nil {
		return err
	}

	if len(errorBuffer.String()) != 0 {
		return errors.New(errorBuffer.String())
	}
	return nil
}

// Delete is a http handler that deletes the files generated by a packet capture
func (f *Files) Delete(w http.ResponseWriter, r *http.Request) {
	log.Infof("Received the following request %s", r.RequestURI)

	if r.Method != http.MethodDelete {
		http.Error(w, "Method not supported", http.StatusMethodNotAllowed)
	}

	var namespace = middleware.NamespaceFromContext(r.Context())
	var captureName = middleware.CaptureNameFromContext(r.Context())
	var clusterID = middleware.ClusterIDFromContext(r.Context())

	packetCapture, err := f.K8sCommands.GetPacketCapture(clusterID, captureName, namespace)
	if err != nil {
		log.WithError(err).Errorf("Failed to get packet capture %s/%s", namespace, captureName)
		switch err.(type) {
		case cerrors.ErrorResourceDoesNotExist:
			http.Error(w, err.Error(), http.StatusNotFound)
			return
		default:
			http.Error(w, err.Error(), http.StatusInternalServerError)
			return
		}
	}

	for _, file := range packetCapture.Status.Files {
		if file.State == nil {
			var err = fmt.Errorf("capture state cannot be determined")
			log.WithError(err).Errorf("Failed delete files for %s/%s", namespace, captureName)
			http.Error(w, err.Error(), http.StatusForbidden)
			return
		}
		if file.State != nil && *file.State != v3.PacketCaptureStateFinished {
			var err = fmt.Errorf("capture state is not Finished")
			log.WithError(err).Errorf("Failed delete files for %s/%s", namespace, captureName)
			http.Error(w, err.Error(), http.StatusForbidden)
			return
		}
	}

	var nodes = make(map[string]struct{})
	for _, file := range packetCapture.Status.Files {
		log.Debugf("Delete files %v", file)
		entryPod, err := f.K8sCommands.GetEntryPod(clusterID, file.Node)
		if err != nil {
			log.WithError(err).Errorf("Failed locate entry pods for %s/%s", namespace, captureName)
			http.Error(w, err.Error(), http.StatusInternalServerError)
			return
		}
		var entryPoint = capture.EntryPoint{
			EntryPod: *entryPod,

			CaptureDirectory: file.Directory,
			CaptureName:      captureName,
			CaptureNamespace: namespace,
		}
		log.Debugf("Entry pods is %v", entryPoint)

		errorReader, err := f.FileCommands.Delete(clusterID, entryPoint)
		if err != nil {
			log.WithError(err).Errorf("Failed create a remote command to retrieve the files from %v", entryPoint)
			http.Error(w, err.Error(), http.StatusInternalServerError)
			return
		}

		// Read the error from the stream
		err = readErrorFromStream(errorReader)
		if err != nil {
			log.WithError(err).Error("Remote command failed")
			http.Error(w, err.Error(), http.StatusInternalServerError)
			return
		}

		nodes[file.Node] = struct{}{}
	}

	if len(nodes) != len(packetCapture.Status.Files) {
		log.WithError(err).Error("Failed to delete files from all known nodes")
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}

	err = f.K8sCommands.UpdatePacketCaptureStatusWithNoFiles(clusterID, captureName, namespace, nodes)
	if err != nil {
		switch err.(type) {
		case cerrors.ErrorResourceUpdateConflict:
			var ctx = context.Background()
			var err = retryFor(ctx, 3, 500*time.Millisecond, 2*time.Second, func() error {
				return f.K8sCommands.UpdatePacketCaptureStatusWithNoFiles(clusterID, captureName, namespace, nodes)
			})
			if err != nil {
				log.WithError(err).Error("Failed to update status for packet capture")
				http.Error(w, err.Error(), http.StatusInternalServerError)
				return
			}
		default:
			log.WithError(err).Error("Failed to update status for packet capture")
			http.Error(w, err.Error(), http.StatusInternalServerError)
			return
		}
	}
}

func retryFor(ctx context.Context, numberOfRetries int, waitBetweenRetries, timeOut time.Duration, f func() error) error {
	ctxWithTimeout, cancel := context.WithTimeout(ctx, timeOut)
	defer cancel()
	var err error
	for i := 0; i < numberOfRetries; i++ {
		select {
		case <-ctxWithTimeout.Done():
			return ctxWithTimeout.Err()
		case <-time.After(waitBetweenRetries):
			err = f()
			if err == nil {
				return nil
			}
		}
	}

	return err
}
